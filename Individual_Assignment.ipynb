{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOolsZ0P7tWxAFtmH0k4J9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marlapinkert/TEWA2/blob/main/Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Individual Assignment\n",
        "\n",
        "The goal of the individual assignment is to perform simple preprocessing, quality checks, and first-level analysis for one singular subject. Check [here](https://docs.google.com/spreadsheets/d/1X4Xi0U9IghWKSXCLe1N6RU-Imar81wNs6ZWjaYIQ5Bg/edit?usp=sharing) to find out which subject is yours to analyse.\n",
        "\n",
        "We will use the \"NYU Slow Flanker\" dataset from [OpenNeuro](https://openneuro.org/datasets/ds000102/versions/00001). In this study, 26 healthy adults underwent MRI scanning while performing an event-related Eriksen Flanker task."
      ],
      "metadata": {
        "id": "JEabm-oaDjSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocessing\n",
        "Before we can start with our analyses, we have to preprocess our data. As we did in the Practicals, we will use Neurodesk, which will provide us with the environment needed to be able to access software such as FSL."
      ],
      "metadata": {
        "id": "-WJxcKbAIIj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up environment\n",
        "The very first steps consist of downloading data and preparing our environment - just run the two cells below. You do not need to change any of the code in there! Remember: If your runtime disconnects, your files get lost and you have to rerun these cells."
      ],
      "metadata": {
        "id": "2-qzUAyODMaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset (all subjects)\n",
        "!mkdir /data\n",
        "!wget 'https://ucloud.univie.ac.at/index.php/s/qKFm0f0Q98etPNG/download' -O /content/ds000102.zip\n",
        "!unzip /content/ds000102.zip -d /data"
      ],
      "metadata": {
        "id": "CGzXvgJTaFtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LD_PRELOAD\"] = \"\";\n",
        "os.environ[\"APPTAINER_BINDPATH\"] = \"/content\"\n",
        "os.environ[\"LMOD_CMD\"] = \"/usr/share/lmod/lmod/libexec/lmod\"\n",
        "\n",
        "!curl -J -O https://raw.githubusercontent.com/NeuroDesk/neurocommand/main/googlecolab_setup.sh\n",
        "!chmod +x googlecolab_setup.sh\n",
        "!./googlecolab_setup.sh\n",
        "os.environ[\"MODULEPATH\"] = ':'.join(map(str, list(map(lambda x: os.path.join(os.path.abspath('/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/'), x),os.listdir('/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/')))))\n",
        "\n",
        "import lmod\n",
        "await lmod.load('fsl/6.0.4')\n",
        "\n",
        "\n",
        "os.environ[\"FSLOUTPUTTYPE\"] = \"NIFTI_GZ\"\n",
        "\n",
        "%cd /data"
      ],
      "metadata": {
        "id": "_8LsiWIFNPwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Functional File\n",
        "Now that the environment is set-up, you can start with the preprocessing. We are keeping it \"simple\" - We will not \"normalize\" our file to the standard template. As we only do first-level analysis, this is not a problem. Your task is to:\n",
        "\n",
        "1. **Calculate additional motion parameters** (`fsl.MotionOutliers`) -> This should be done on the raw file\n",
        "2. **Perform slicetiming correction** (`fsl.SliceTimer`) -> This should be done on the raw file.\n",
        "  \n",
        "    **Note:** Although this information is lacking in the NIfTI header, we know from [Mennes et al. (2011)]( https://doi.org/10.1016/j.neuroimage.2010.10.046) that the study used an interleaved acquisition order. Make sure to specify this!\n",
        "\n",
        "3. **Perform Motion correction** (`fsl.MCFLIRT`) -> This should be done on the slicetime-corrected file.\n",
        "\n",
        "    **Note:** Make sure to save the motion parameters, so you can plot them later!\n",
        "\n",
        "4. **Perform Smoothing** (`fsl.IsotropicSmooth`) -> This should be done on the motion-corrected file..\n",
        "\n",
        "    **Note**: Make sure to specify an FWHM  of 6.\n",
        "\n",
        "Tip 1: in the practicals, we used the `.outputs` attribute of Nipype interface results to access the paths to the processed files directly. You can also do this manually, but it is more tedious.\n",
        "\n",
        "Tip 2: Using Nipype within Colab can cause issues if paths are not specified in a certain way. You are usually on the safe side if you provide the absolute path.\n",
        "\n"
      ],
      "metadata": {
        "id": "VCBOFk48DPbK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkgszXt-bder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Preprocessed Images\n",
        "Plot both the raw and preprocessed images. Make sure to set a title for each. Comment on which differences you observe."
      ],
      "metadata": {
        "id": "EYZ2JzrISCXY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gpteWWIobebT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Quality Check - Motion Parameters\n",
        "\n",
        "To recap the lecture, there are six motion parameters: 3 corresponding to translation (in x, y, z direction, respectively) and 3 corresponding to rotation (pitch, roll, yaw, respectively).\n",
        "\n",
        "During preprocessing, we made sure to calculate these motion parameters by using `fsl.MCFLIRT`. We also calculated additional parameters with `fsl.MotionOutliers`. You will now:\n",
        "\n",
        "1. **Plot the motion parameters**.\n",
        "  \n",
        "  Note: Your result should look something like the plots shown in the lecture and practical - you should have one plot for translation and one for rotation.\n",
        "2. Calculate the **mean and maximum framewise displacement**.\n",
        "3. **Describe** what the plots tell you - how much and in which directions did the participant move? How much framewise displacement was there? Do feel like this was too much movement?\n",
        "\n",
        "**Bonus**:\n",
        "\n",
        "  Create an additional plot, plotting the motion parameters as you did before. However, this time, also plot at which timepoints participants had to \"press the button\". i.e., respond to the task. This information is contained in the events file (ends in .tsv). Tip: The onset is given in seconds, but your plot just uses the timepoints (TRs).\n",
        "\n",
        "  Is there a relation between movement and task?"
      ],
      "metadata": {
        "id": "-sWgYmj5GTBq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-HB0EccbfSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. First-Level Analysis\n",
        "\n",
        "Using the preprocessed functional file, perform a first-level analysis. The steps are:\n",
        "\n",
        "1. **Set-up Model** (using Nilearn's ```FirstLevelModel```)\n",
        "\n",
        "2. **Fit the model** to the data\n",
        "  - use the events file stored in the data directory\n",
        "  - use the motion parameters as additional regressors\n",
        "  \n",
        "  \n",
        "3. Plot the **design matrix**\n",
        "4. Define the **contrasts**\n",
        "  - congruent_correct > baseline\n",
        "  - incongruent_correct > baseline\n",
        "  - incongruent-congruent\n",
        "  - congruent-incongruent\n",
        "  - motion parameters > baseline\n",
        "5. Calculate a **z-statistics map** for each contrast\n",
        "6. Calculate a **statistical threshold** for each contrast\n",
        "7. **Plot** the z-statistics maps (using the subject's anatomical image as background)\n"
      ],
      "metadata": {
        "id": "xezy4NkUUhxk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0qmZdDxbf2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}