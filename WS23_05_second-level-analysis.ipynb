{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/3DoUQ34q9TubGUFjfeUA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"u1ZIW8mDdAFN"},"source":["# 07 -  Second Level Analysis"]},{"cell_type":"markdown","metadata":{"id":"DQagFfdedAFR"},"source":["## Download data and install dependencies"]},{"cell_type":"markdown","metadata":{"id":"KUkP95AgdAFR"},"source":["For the group aissgnments, we will provide you with single-subject contrast maps based on which you can perform the second level (or: group level) analysis and report the results. In this notebook, we will work with data included in Nilearn, specifically using the ```fetch_localizer_contrasts()``` function, which qives access to a wide range of functional localizer contrasts (for further infos see [here](https://osf.io/vhtf6))."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EK2ZISVdAFS"},"outputs":[],"source":["!pip install nilearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-ErgAMcdAFT"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from nilearn import datasets, plotting, image\n","from pprint import pprint"]},{"cell_type":"markdown","metadata":{"id":"kipSAbJ_NN_R"},"source":["For illustration purposes, we will only the right vs. left button press for a total of 20 participants."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2a_d3JUdAFV"},"outputs":[],"source":["n_subjects = 20\n","\n","con_left_right = datasets.fetch_localizer_contrasts([\"right vs left button press\"],\n","                                                    n_subjects)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-p1ppDutdAFV"},"outputs":[],"source":["print(f\"data is stored in: {datasets.get_data_dirs()[0]}\")"]},{"cell_type":"markdown","metadata":{"id":"k5r7Df-9dAFW"},"source":["Now we need to find a way to access the respective contrast maps (one contrast for each subject). The ```glob``` module from the Python standard library can help us here. It provides a nice way to list the contens of given paths:"]},{"cell_type":"markdown","metadata":{"id":"ohqWpGo4Zld7"},"source":["Now we need to find a way to access the respective contrast maps (one contrast for each subject). The ```glob``` module from the Python standard library can help us here. It provides a nice way to list the contens of given paths:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mo4JjtF1dAFX"},"outputs":[],"source":["from glob import glob\n","\n","cmaps = sorted(\n","    glob(f\"{datasets.get_data_dirs()[0]}/brainomics_localizer/brainomics_data/**/*.nii.gz\",\n","         recursive=True)\n",")\n","\n","pprint(cmaps)\n","print(f\"\\nThere are {len(cmaps)} contrast maps\")"]},{"cell_type":"markdown","metadata":{"id":"y-g3DFuzdAFa"},"source":["Before we move on, let's define a BIDS style subject list (i.e., \"sub-01\", \"sub-02\" etc.). We can do this in one line using a [List comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) and some [string formatting](https://docs.python.org/3/reference/lexical_analysis.html#f-strings):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w97feMFRdAFa"},"outputs":[],"source":["subject_list = [f\"sub-{i:02d}\" for i in range(1, n_subjects + 1)]\n","pprint(subject_list)"]},{"cell_type":"markdown","metadata":{"id":"1wNxkke1dAFb"},"source":["## Basic Second-level model\n","\n","To remind you, in the first-level analysis we summarized the data using a linear contrasts of our predictors (or: regressors). This was done *per* subject and allows us to model the experimental design. Now, the goal is to use the resulting contrast maps to summarize the evidence over all subjects, increasing statistical power.\n"]},{"cell_type":"markdown","metadata":{"id":"pC2TzDPEdAFc"},"source":["### Set up Model\n","\n","Now that we our contrast maps in place, we have to define a design matrix (i.e., our independent variables) for the given statistical test we want to perform. The design matrix should be specified as a ```pandas``` dataframe. Also, it should have as many rows as there are contrast maps (one contrast map per subject; the respective contrast values of each voxel will serve as the dependent variables; note that we will follow a mass univariate approach just as in the first-level analysis).\n","\n","For now, we will only include an intercept in our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GocP4fC_dAFc"},"outputs":[],"source":["# one sample t-test: only intercept needed\n","\n","design_matrix = pd.DataFrame([1] * n_subjects,\n","                             columns = [\"intercept\"],\n","                             index = subject_list)\n","\n","design_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmSU9HWkdAFd"},"outputs":[],"source":["from nilearn.glm.second_level import SecondLevelModel\n","\n","second_level = SecondLevelModel(n_jobs=2)\n","second_level = second_level.fit(cmaps, design_matrix = design_matrix)"]},{"cell_type":"markdown","metadata":{"id":"WVWGsb4CdAFd"},"source":["Great, now that we have fitted our second level design matrix to the first-level contrast maps, we can go ahead and calculate a second-level contrast. Say we want to know whether a right vs. a left button press elicits a statistically significant activation across all subjects. That is, we want to compute the average group level contrast of \"right vs. left button press\". We can do this by evaluating the intercept contrast:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvELdBOTdAFd"},"outputs":[],"source":["right_left_avg = second_level.compute_contrast(second_level_contrast = \"intercept\",\n","                                               output_type = \"z_score\")"]},{"cell_type":"markdown","source":["Let's have a look at the resulting statistical map. To get a better feeling will set an arbitrary threshold of 3:"],"metadata":{"id":"J-DTYPJeQP8C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OV8k6Xx0dAFd"},"outputs":[],"source":["plotting.plot_stat_map(right_left_avg, threshold=3)"]},{"cell_type":"markdown","metadata":{"id":"TD8BNwOBdAFe"},"source":["### Hypothetical group comparison\n","\n","Let's say we want to compare older vs. younger adults (i.e., compare two groups). To do so, we have to specify our design matrix in a specific way. For illustration purposes, let's just assume the first 10 subject of the localizer dataset are young adults, while the latter 10 subjects are older adults.\n","\n","We start by including an intercept (just as we did above)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sfp-u-ndAFf"},"outputs":[],"source":["design_matrix_groups = pd.DataFrame([1] * n_subjects,\n","                                    columns = [\"intercept\"],\n","                                    index = subject_list)"]},{"cell_type":"markdown","metadata":{"id":"GcC2E_80dAFf"},"source":["As a next step, we initialize columns that will indicate group membership. That is, we will create a new column for each group."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y67aVqMdAFf"},"outputs":[],"source":["# start by initializing the group dummy columns\n","design_matrix_groups[\"group_young\"] = 0\n","design_matrix_groups[\"group_old\"]   = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rq5dZX7e0ZH"},"outputs":[],"source":["design_matrix_groups"]},{"cell_type":"markdown","metadata":{"id":"G1n4c8MQdAFf"},"source":["Next, we will define the group membership. Remember that the rows of our design matrix correspond to the respective contrast maps. We know that the first 10 subjects (i.e., the first 10 contrast maps) are young adudlts, so we will set the first 10 entries of the column ```group_young``` to 1, the remaining rows will stay 0. Analogously, we set the last 10 entries of the ```group_old``` to 1.\n","\n","Note: It is very important that the order of the contrast maps matches the respective entries in the design matrix (i.e., make sure that the first 10 contrast maps belong to young adults)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GG3Tj9xCdAFg"},"outputs":[],"source":["design_matrix_groups.loc[subject_list[:10], \"group_young\"] = 1\n","design_matrix_groups.loc[subject_list[10:], \"group_old\"] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWli6ybzdAFg"},"outputs":[],"source":["design_matrix_groups"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqarUzlhdAFg"},"outputs":[],"source":["second_level = SecondLevelModel(n_jobs=2)\n","second_level = second_level.fit(cmaps, design_matrix = design_matrix_groups)"]},{"cell_type":"markdown","metadata":{"id":"S46-Of7PNN_U"},"source":["In practise, information regarding group membership or other participant-specific data is often stored in a separate [participants file](https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#participants-file). Thus, you would use this file to set up a second level design matrix as above."]},{"cell_type":"markdown","metadata":{"id":"ICl36uGZdAFg"},"source":["### Define second level contrasts\n","\n","Now that we have fitted the model to the data, we will have compute some contrasts in order to make inferences about the data (that is, we assign weights to our parameters). For this, we will set up a contrast matrix.\n","\n","We start by defining an identity matrix (using ```np.eye```) with a shape corresponding to the number of columns in our design matrix (we could also write out the contrast vectors manually as we did in the first level analysis notebook)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DcAx7J3dAFg"},"outputs":[],"source":["contrast_matrix = np.eye(design_matrix_groups.shape[1])"]},{"cell_type":"code","source":["contrast_matrix"],"metadata":{"id":"jJbXeuZjkHKP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6F6MptI1dAFh"},"source":["With this contrast matrix we could test three contrasts. The first contrast (first row in the contrast matrix) would test the average effect across all subjects (intercept set to 1). The second one would test the average in the group of younger adults. Finally, the third one would test the average in the group of younger adults.\n","\n","For the sake of clarity, let's define a dictionary in which we can assign a verbal label to the contrasts. Here, we will also use a list comprehension:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWvCXTRpdAFh"},"outputs":[],"source":["contrasts = dict(\n","    [(column, contrast_matrix[i]) for i, column in enumerate(design_matrix_groups.columns)]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQkyiZoddAFh"},"outputs":[],"source":["pprint(contrasts)"]},{"cell_type":"markdown","metadata":{"id":"S1HZUZ_idAFk"},"source":["Cool, but what if we are interested in comparing younger and older adults? For this we would have to define further contrast(s).\n","\n","Just as in the first level analysis we have to set one group (or condition in the 1st level) to 1 and the other one to -1. We can do this by simply subtracting the contrasts from one another:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB7gc53vdAFk"},"outputs":[],"source":["contrasts['group_old-young'] =  contrasts['group_old'] - contrasts['group_young']\n","contrasts['group_young-old'] = -contrasts['group_old'] + contrasts['group_young']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQz-GuEqdAFk"},"outputs":[],"source":["pprint(contrasts)"]},{"cell_type":"markdown","metadata":{"id":"uamjFvUUdAFk"},"source":["Now that we have defined our contrasts, we can go ahead an acutally calculate them. We will do this using a simple ```for``` loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rs-f3tEzdAFk"},"outputs":[],"source":["cmaps_second = {con: None for con in contrasts}\n","\n","for con in contrasts:\n","    print(f'\\nRunning {con}...')\n","    print(f' - Calculating contrast...')\n","    res = second_level.compute_contrast(contrasts[con], output_type='z_score')\n","    cmaps_second[con] = res\n","    print( 'done.')"]},{"cell_type":"markdown","metadata":{"id":"7PFAXpVZNN_V"},"source":["### Correcting for multiple comparisons\n","\n","As in the first level analysis, we need to correct for multiple comparisons in the second level analysis. Before we do so, let's have a look at the raw z-map (or: the untresholded map).\n","\n","*Since the group comparisons were just hypothetical we will only look at the intercept contrast, i.e., the grand average*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Iqq35TRNN_V"},"outputs":[],"source":["disp  = plotting.plot_stat_map(cmaps_second[\"intercept\"],\n","                               title='Raw z map')"]},{"cell_type":"markdown","metadata":{"id":"g3V2uqf-NN_V"},"source":["Now, let's correct for mulitple comparisons. As you know there are different approaches to do is. Here, we will just look at the *false discovery rate* (which doesn't mean this is the preferred approach for every research question). Specifically, we will use an alpha level of 0.05 and set the cluster-defining threshold to an arbitrary number of 10 voxels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0OEwmTqNN_V","outputId":"be9e2a22-ba1f-49b8-e1be-6c1868a9c05d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["The FDR=.05 threshold is 3.197\n"]}],"source":["from nilearn.glm import threshold_stats_img\n","\n","thresholded_map, threshold = threshold_stats_img(\n","    cmaps_second[\"intercept\"],\n","    alpha=.05, height_control='fdr', cluster_threshold=10)\n","\n","print(f\"The FDR=.05 threshold is {round(threshold, 3)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STrDHeh7NN_V"},"outputs":[],"source":["plotting.plot_stat_map(thresholded_map, cut_coords=disp.cut_coords,\n","                       title=\"Thresholded z map, expected fdr = .05, clusters = 10\",\n","                       threshold=threshold)"]},{"cell_type":"markdown","metadata":{"id":"nhbrnfQGNN_V"},"source":["Again, there are different approaches to correct for multiple comparisons (for example, non-parametric approches such as permutation testing are becoming more and more common). Check out the [Nilearn user guide](https://nilearn.github.io/dev/glm/second_level_model.html#multiple-comparisons-correction) to see which routines are implemented in the package."]},{"cell_type":"markdown","metadata":{"id":"mE_eFAOsdAFl"},"source":["## Store objects"]},{"cell_type":"markdown","metadata":{"id":"PagAP8zwfS33"},"source":["Since setting up and fitting models as well computing contrasts can take some time, it would nice to be able to preserve the results of these computations (especially when working in Colab). Luckily, the ```pickle``` module from Python's standard library can help us here. It provides a way to save Python objects to files."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aj7ySqcvdAFl"},"outputs":[],"source":["import pickle"]},{"cell_type":"markdown","metadata":{"id":"qmLRxg58gDNn"},"source":["Objects can be stored by using the ```dump``` function. All it takes is the name of the object we want to save as well as the file name (which needs to be passed to the ```open``` function; here, ```wb``` stands for \"write binary\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ord3qbQEdAFl"},"outputs":[],"source":["pickle.dump(second_level, open(\"/content/second_level.pkl\", \"wb\"))"]},{"cell_type":"code","source":["!ls /content"],"metadata":{"id":"UVNBdO-jU2Lv","outputId":"b87948b1-d11c-4a2c-fdd1-3f444989c19c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data  second_level.pkl\n"]}]},{"cell_type":"markdown","source":["Next, we unpickle the object - here, we use ```rb``` (i.e., read binary) as the parameter to the ```open``` function"],"metadata":{"id":"bHg3a9BMU9Jk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HgG-P5-dAFl"},"outputs":[],"source":["secondlvl_pkl = pickle.load(open(\"/content/second_level.pkl\", \"rb\"))"]},{"cell_type":"markdown","metadata":{"id":"ixzdAy6rdAFl"},"source":["After unpickling the object, we have access to the usual attributes and methods and parameters of the second level object. For example, it still contains our previously defined design matrix:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQk_INE0dAFl"},"outputs":[],"source":["secondlvl_pkl.design_matrix_"]},{"cell_type":"markdown","metadata":{"id":"il0HZ4UsdAFm"},"source":["As we have pickled the already fitted object, we can go ahead and evaluate some contrasts (without fitting the model again):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpwQ4sbodAFm"},"outputs":[],"source":["right_left_pkl = secondlvl_pkl.compute_contrast(\n","    second_level_contrast = \"intercept\", output_type = \"z_score\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMMXIU6jdAFm"},"outputs":[],"source":["plotting.plot_stat_map(right_left_pkl, threshold=3)"]},{"cell_type":"markdown","metadata":{"id":"9F_EfZ0UNN_W"},"source":["## Resources\n","\n","[Nilearn user guide on second level models](https://nilearn.github.io/dev/glm/second_level_model.html#)\n","Here you can find links to different tutorials covering how to perform second level analyses with Nilearn. Included are (among others) overviews on:\n","\n","\n","- [Statistical testing of a second-level analysis](https://nilearn.github.io/dev/auto_examples/05_glm_second_level/plot_thresholding.html#sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py)\n","\n","- [Basic one sample t test](https://nilearn.github.io/dev/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html)\n","  - includes different strategies for multiple comparison correction, e.g. non-parametric inference"]}]}
